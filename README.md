## Project Overview
This project focuses on testing adversarial attacks across various models and datasets, specifically targeting image classification models. The core idea is to evaluate the resilience of these models against adversarial threats in a structured manner.

### Key Features
----
 - Adversarial Attack Testing: Systematic evaluation of image classification models against adversarial attacks.

 - Integration with [TorchAttacks](https://github.com/Harry24k/adversarial-attacks-pytorch/): Utilizes TorchAttacks for implementing adversarial attacks, serving as a seamless replacement for traditional methods.

 - Hugging Face Models: Leverages models from Hugging Face to train on specific datasets and assess their performance under adversarial conditions.

 - Live Inference Script: Includes a script for real-time model inference using a webcam, allowing for dynamic testing environments.
### Contributing
---
In general we would want for the project to have the following things , so any contributions to this areas will be well welcome.

- Configuration Flexibility: Aim to enhance project configurability using files like YAML, making it easily adaptable for different users and scenarios.

- Feature Enhancements: Contributions that introduce new functionalities or features to improve adversarial attack testing are highly encouraged. Feel free to create an issue to discuss your ideas.


Exporting TensorRT engine.

For exporting a trt model and use it in the live_inference script you first must ensure that you  have CUDA and tensorRT installed in your machine.

# Getting Started:
Not yet ready for this.